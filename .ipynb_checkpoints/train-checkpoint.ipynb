{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#  Initializing the training and validation generators:\n",
    "\n",
    "train_dir = 'C:\\\\Users\\\\Saurav\\\\Desktop\\\\emojify 2\\\\Dataset\\\\archive\\\\train'\n",
    "val_dir = 'C:\\\\Users\\\\Saurav\\\\Desktop\\\\emojify 2\\\\Dataset\\\\archive\\\\test'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Building the convolution neural network architecture:\n",
    "\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saurav\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Saurav\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "448/448 [==============================] - 469s 1s/step - loss: 1.8030 - accuracy: 0.2611 - val_loss: 1.7238 - val_accuracy: 0.3504\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 161s 360ms/step - loss: 1.6383 - accuracy: 0.3591 - val_loss: 1.5650 - val_accuracy: 0.4083\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 173s 387ms/step - loss: 1.5398 - accuracy: 0.4062 - val_loss: 1.4747 - val_accuracy: 0.4342\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 160s 356ms/step - loss: 1.4727 - accuracy: 0.4359 - val_loss: 1.4272 - val_accuracy: 0.4547\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 159s 354ms/step - loss: 1.4117 - accuracy: 0.4604 - val_loss: 1.3662 - val_accuracy: 0.4830\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 152s 339ms/step - loss: 1.3643 - accuracy: 0.4786 - val_loss: 1.3266 - val_accuracy: 0.4965\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 257s 574ms/step - loss: 1.3200 - accuracy: 0.5015 - val_loss: 1.2957 - val_accuracy: 0.5050\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 149s 332ms/step - loss: 1.2793 - accuracy: 0.5149 - val_loss: 1.2622 - val_accuracy: 0.5172\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 141s 316ms/step - loss: 1.2449 - accuracy: 0.5300 - val_loss: 1.2357 - val_accuracy: 0.5329\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 143s 319ms/step - loss: 1.2181 - accuracy: 0.5414 - val_loss: 1.2438 - val_accuracy: 0.5216\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 141s 316ms/step - loss: 1.1837 - accuracy: 0.5573 - val_loss: 1.2086 - val_accuracy: 0.5378\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 269s 601ms/step - loss: 1.1611 - accuracy: 0.5631 - val_loss: 1.1755 - val_accuracy: 0.5498\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 214s 477ms/step - loss: 1.1270 - accuracy: 0.5773 - val_loss: 1.1571 - val_accuracy: 0.5596\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 137s 305ms/step - loss: 1.1116 - accuracy: 0.5822 - val_loss: 1.1470 - val_accuracy: 0.5636\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 139s 310ms/step - loss: 1.0822 - accuracy: 0.5929 - val_loss: 1.1370 - val_accuracy: 0.5679\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 139s 311ms/step - loss: 1.0592 - accuracy: 0.6037 - val_loss: 1.1388 - val_accuracy: 0.5705\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 143s 318ms/step - loss: 1.0361 - accuracy: 0.6130 - val_loss: 1.1235 - val_accuracy: 0.5755\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 138s 309ms/step - loss: 1.0119 - accuracy: 0.6225 - val_loss: 1.1182 - val_accuracy: 0.5799\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 139s 310ms/step - loss: 0.9917 - accuracy: 0.6331 - val_loss: 1.1116 - val_accuracy: 0.5850\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 148s 331ms/step - loss: 0.9680 - accuracy: 0.6413 - val_loss: 1.0994 - val_accuracy: 0.5854\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 151s 337ms/step - loss: 0.9492 - accuracy: 0.6495 - val_loss: 1.1012 - val_accuracy: 0.5875\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 153s 342ms/step - loss: 0.9199 - accuracy: 0.6584 - val_loss: 1.1192 - val_accuracy: 0.5845\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 158s 353ms/step - loss: 0.8993 - accuracy: 0.6639 - val_loss: 1.0891 - val_accuracy: 0.5936\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 157s 350ms/step - loss: 0.8802 - accuracy: 0.6755 - val_loss: 1.0933 - val_accuracy: 0.5988\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 156s 349ms/step - loss: 0.8567 - accuracy: 0.6837 - val_loss: 1.0923 - val_accuracy: 0.5951\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 157s 349ms/step - loss: 0.8294 - accuracy: 0.6943 - val_loss: 1.0765 - val_accuracy: 0.6088\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 158s 352ms/step - loss: 0.8069 - accuracy: 0.7035 - val_loss: 1.0815 - val_accuracy: 0.6004\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 232s 518ms/step - loss: 0.7952 - accuracy: 0.7116 - val_loss: 1.0905 - val_accuracy: 0.6060\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 170s 380ms/step - loss: 0.7673 - accuracy: 0.7176 - val_loss: 1.0867 - val_accuracy: 0.6085\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 167s 373ms/step - loss: 0.7444 - accuracy: 0.7306 - val_loss: 1.0801 - val_accuracy: 0.6116\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.7221 - accuracy: 0.7322 - val_loss: 1.0803 - val_accuracy: 0.6148\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 417s 931ms/step - loss: 0.6995 - accuracy: 0.7476 - val_loss: 1.0926 - val_accuracy: 0.6144\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.6803 - accuracy: 0.7530 - val_loss: 1.0891 - val_accuracy: 0.6165\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 172s 385ms/step - loss: 0.6633 - accuracy: 0.7585 - val_loss: 1.0887 - val_accuracy: 0.6126\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 165s 368ms/step - loss: 0.6382 - accuracy: 0.7679 - val_loss: 1.0852 - val_accuracy: 0.6222\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 162s 361ms/step - loss: 0.6142 - accuracy: 0.7740 - val_loss: 1.0963 - val_accuracy: 0.6170\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 156s 349ms/step - loss: 0.5962 - accuracy: 0.7837 - val_loss: 1.1031 - val_accuracy: 0.6148\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 158s 354ms/step - loss: 0.5760 - accuracy: 0.7918 - val_loss: 1.1059 - val_accuracy: 0.6219\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 177s 396ms/step - loss: 0.5602 - accuracy: 0.7978 - val_loss: 1.1011 - val_accuracy: 0.6236\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 162s 360ms/step - loss: 0.5353 - accuracy: 0.8058 - val_loss: 1.1170 - val_accuracy: 0.6203\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 158s 351ms/step - loss: 0.5159 - accuracy: 0.8113 - val_loss: 1.1390 - val_accuracy: 0.6198\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 157s 351ms/step - loss: 0.5103 - accuracy: 0.8158 - val_loss: 1.1322 - val_accuracy: 0.6239\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 157s 351ms/step - loss: 0.4919 - accuracy: 0.8245 - val_loss: 1.1259 - val_accuracy: 0.6236\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 159s 354ms/step - loss: 0.4735 - accuracy: 0.8294 - val_loss: 1.1592 - val_accuracy: 0.6265\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 156s 348ms/step - loss: 0.4547 - accuracy: 0.8355 - val_loss: 1.1753 - val_accuracy: 0.6256\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 157s 350ms/step - loss: 0.4452 - accuracy: 0.8373 - val_loss: 1.1756 - val_accuracy: 0.6289\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 158s 352ms/step - loss: 0.4280 - accuracy: 0.8484 - val_loss: 1.2000 - val_accuracy: 0.6271\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 156s 349ms/step - loss: 0.4169 - accuracy: 0.8478 - val_loss: 1.1824 - val_accuracy: 0.6254\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 157s 351ms/step - loss: 0.4065 - accuracy: 0.8539 - val_loss: 1.2093 - val_accuracy: 0.6264\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 159s 354ms/step - loss: 0.3894 - accuracy: 0.8593 - val_loss: 1.2032 - val_accuracy: 0.6228\n"
     ]
    }
   ],
   "source": [
    "#  Compiling and training the model:\n",
    "\n",
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)\n",
    "\n",
    "#   Saving the model weights:\n",
    "\n",
    "emotion_model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
